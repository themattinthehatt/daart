# currently supported: temporal-mlp, lstm, gru, tcn, dtcn
model_type: lstm

# hidden layers for both classifier and predictor networks
n_hid_layers: 1

# hidden units per layer
n_hid_units: 32

# half-width of temporal convolution window for temporal-mlp
n_lags: 16

# layer nonlinearity
activation: relu

# hyperparam on classifying weak labels
lambda_weak: 1

# hyperparam on classifying strong labels
lambda_strong: 1

# hyperparam on one-step-ahead prediciton
lambda_pred: 1

# name of experiment for test-tube organizing
tt_experiment_name: test

# control initialization of model
rng_seed_model: 0

# bidirectionality of RNNs (LSTM, GRU)
bidirectional: true

# dropout for individual channels of dilated TCN models (soon to be for others)
dropout: 0.1
